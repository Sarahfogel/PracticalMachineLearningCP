{
    "contents" : "---\ntitle: \"Practical Machine Learning Course Project\"\nauthor: \"Sarah Fogel\"\ndate: \"Wednesday, May 20, 2015\"\noutput: html_document\n---\n##Synopsis\nThis report adresses the creation of a prediction algorithm for determining the class of bicep curl (correct form or one of four incorrect forms) based on input from sensors on various points on a person's body.  This analysis finds that a random forest prediction provides the best chance for correct predictions.\n\n\n##Data Processing and Exploratory Analysis\nThe data is first read in as-is from a downloaded file in the working directory.\nIt is split into a training set and a testing set\n\n```{r, echo=FALSE, cache=TRUE}\n\n# Read the files in\n\n    training<-read.csv(\"pml-training.csv\", header=T)\n    testing<-read.csv(\"pml-testing.csv\", header=T)\n\n```\n\nThen we take a look at the data in the training set to begin identifying possible transformations that should be performed or variables that should be removed from consideration.  The test set will be ignored during the analysis except to perform the same transformations on that data as are done to the training set.\n\nMost of the results of the exploration will not be reproduced here for the sake of brevity.\n\n```{r}\n# How big is the data set?\n    dim(training)\n# What are the variables in the data set?\n    head(names(training), 15)\n```\nSince it would be ideal for a prediction algorithm to be applicable regardless of the particular user or any variable related to when the bicep curl was performed, those varibles, as well as the index, will be removed. \n\nMany of the variables have more than 95% of the observations missing.  It was assumed that this data would a) likely be missing in any new data collected and b) unlikely to contribute much to tuning a prediction algorithm, so all of those variables were removed.\n\nAt the same time as a \"clean\" training set was created, a valdiation set was partitioned off to allow for \"out of sample\" validation later on in the prediction algorithm selection process.  20% of the training set was used for this validation set.\n\n```{r, include=FALSE}\n    library(caret)\n    set.seed(3450)\n\n    trainIndex<-createDataPartition(training[,160], p=.8, list=FALSE)\n\n    validationclean<-training[-trainIndex,-c(1:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150)]\n    trainingclean<-training[trainIndex, -c(1:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150)]\n    testingclean<-testing[-c(1:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150)]\n```\n\nThe remaining varibles were examined for low variability, which would indicate that they are unlikely to contribute substantially to a prediction algorithm.\n\nNumber of variables with near zero variability:\n```{r, echo=FALSE}\n    nzv<- nearZeroVar(trainingclean, saveMetrics=TRUE)\n    sum(nzv$nzv)\n```\n\nNo variables were found to have near zero variability.\n\nThe 53 variables remaining in the data set are: roll, pitch, and yaw of each of 4 sensors(12); total acceleration of 4 sensors(4); acceleration in 3 directions of 4 sensors (12); gyroscopic forces in 3 directions on 4 sensors (12); magnetic force in 3 directions on 4 sensors (12); and class of exercise (1)\n\nMany of the remaining variables are non-normal; many were bi-modal in shape and some were skewed.  No transformations were performed because the prediction methods used were primarily non-linear and could handle non-normal data.  A sample of the varibles are plotted below to demonstrate the variety of distributions.\n\n```{r, echo=FALSE}\n    par(mfrow=c(2,2))\n    for (i in 21:24) {\n        hist(trainingclean[,i], main=paste(names(trainingclean)[i]), xlab=\"\", col=\"steelblue\")\n    }\n    par(mfrow=c(1,1))\n```\n\n##Model Building and Selection\n\nSeveral models were fit using the caret package on the training data.  These were a classification tree model (rpart), a random forest model (rf), a random forest model using principal components (rf.pca), and a stochastic gradient boosting model (gbm).\n\n```{r, include=FALSE, cache=TRUE,}\n    set.seed(333)\n# Classification tree\n    rpart.model<-train(trainingclean[,1:52], trainingclean[,53], method=\"rpart\")\n# Random Forrest\n    rf.model<-train(trainingclean[,1:52], trainingclean[,53], method=\"rf\")\n\n# Prepare principal components\n    preProc<-preProcess(trainingclean[,1:52], method=\"pca\", thresh=.9)\n    pcatrain<- predict(preProc, trainingclean[,1:52])\n    pcavalidation<- predict(preProc,validationclean[,1:52])\n\n# Principal components random forrest\n    rf.pca.model<-train(pcatrain, trainingclean[,53], method=\"rf\")\n\n# Stochastic gradient boosting model\n    gbm.model<-train(trainingclean[,1:52], trainingclean[,53], method=\"gbm\")\n\n```\n\nEach of these models was created using bootstrapping validation to select the parameters.  Since the parameters were selected using this form of validation, another form must be used to estimate the out of sample error.  This was determined by comparing the bicep curl classes in the validation set (which was removed from the training set prior to training the models) to the predicted values based on each model.  The results for each model are listed below:\n\n```{r, include=FALSE}\n    library(rpart)\n    library(randomForest)\n    library(gbm)\n    library(plyr)\n```\n\nClassification Tree Model\n```{r, echo=FALSE}\n    confusionMatrix(validationclean[,53], predict(rpart.model, validationclean[,1:52]))\n```\n\nRandom Forest Model\n```{r, echo=FALSE}\n    confusionMatrix(validationclean[,53], predict(rf.model, validationclean[,1:52]))\n```\n\nRandom Forest Model using Principal Components\n```{r, echo=FALSE}\n    confusionMatrix(validationclean[,53], predict(rf.pca.model, pcavalidation))\n```\n\nStochastic Gradient Boosting Model\n```{r, echo=FALSE}\n    confusionMatrix(validationclean[,53], predict(gbm.model, validationclean[,1:52]))\n```\n\nThe higest out of sample accuracy for any of these models is the random forrest model.  Therefore, that will be the selected model.\n\nThe expected out of sample accuracy for this model is .99.\n\n##Predicting with the Model\n\nThe random forest model can now be applied to the test set to make the final predictions.  The predictions for the test set were submitted through the online submission function and all were rated correct.\n\n\n",
    "created" : 1432135576807.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1453851545",
    "id" : "B8BA651C",
    "lastKnownWriteTime" : 1432220484,
    "path" : "P:/Education/Coursera Courses/Practical Machine Learning/PracticalMachineLearningCP/Practical Machine Learning CP Final.Rmd",
    "project_path" : "Practical Machine Learning CP Final.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}