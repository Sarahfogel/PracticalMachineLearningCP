{
    "contents" : "#==============================================================================\n#\n# Exploratory Analysis for Practical Machine Learning Course Project\n#\n#==============================================================================\n\n\n#=======================Download and Read in Files=============================\n\n# First Download the files, if they haven't already been downloaded\n\n    if (\"pml-training.csv\" %in% list.files(\".\")) {\n        \n    } else { print(\"downloading\")\n        download.file(\n            \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\",\n            destfile=\"./pml-training.csv\")\n    }\n\n    if (\"pml-testing.csv\" %in% list.files(\".\")) {\n        \n    } else { print(\"downloading\")\n             download.file(\n                 \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\",\n                 destfile=\"./pml-testing.csv\")\n    }\n\n# Now read the files in\n\n    training<-read.csv(\"./pml-training.csv\", header=T)\n    testing<-read.csv(\"./pml-testing.csv\", header=T)\n\n\n#==========================Explore Data=========================================\n\n# There are 160 variables and nearly 20000 observations in this dataset\n\n    summary(training[,1:20])\n    summary(training[,21:40])\n    summary(training[,41:60])\n    summary(training[,61:80])\n    summary(training[,81:100])\n    summary(training[,101:120])\n    summary(training[,121:140])\n    summary(training[,141:160])\n\n# List of variables that should be removed: X - just an index, time stamps (x3) - time\n#    shouldn't matter, new_window and num-window - what is that?,\n# Anything that has 19216 NAs or more - these only have a 2% chance of having data:\n#   columns 12:36, 50:59, 69:83, 87:101, 103:112, 125:139, 141:150\n\n\n    dim(training[-c(1,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )])\n\n# Create new training and testing sets with the irrelevant variables removed\n\n    trainingclean<-training[-c(1,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]\n    testingclean<-testing[-c(1,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]\n\n# Also, create a vector containig the actual outcome we're interested in for this analysis\n#   correct or not, not which class of incorrect\n\n    outcomes<-factor(levels=c(\"Right\", \"Wrong\"))\n    for (i in 1:dim(trainingclean)[1]) {\n        if (trainingclean[i,54]==\"A\"){\n            outcomes[i]<-\"Right\"\n        } else {\n            outcomes[i]<-\"Wrong\"\n        }\n    }\n\n# Continue exploring\n    summary(trainingclean)\n\n# The 54 variables we have left are: person(1); roll, pitch, and yaw of each of 4 sensors(12); \n#   total acceleration of 4 sensors(4); acceleration in 3 directions of 4 sensors (12);\n#   gyroscopic forces in 3 directions on 4 sensors (12); \n#   magnetic force in 3 directions on 4 sensors (12); and class of exercise (1)\n\n# Check if total acceleration adds anything over the 3 directions\n    d<-(sqrt(accel_belt_x^2+accel_belt_y^2+accel_belt_x^2)-total_accel_belt)\n    head(d)\n\n    d2<-(sqrt(roll_belt^2+pitch_belt^2+yaw_belt^2)-total_accel_belt)\n    head(d2)\n\n    d3<-(sqrt(gyros_belt_x^2+gyros_belt_y^2+gyros_belt_x^2)-total_accel_belt)\n    head(d3)\n\n    head(total_accel_belt)\n\n# Look for variables with near 0 variability\n\n    nsv<- nearZeroVar(trainingclean, saveMetrics=TRUE)\n    nsv\n\n    #No variables come out small variation\n\n# Look for highly correlated variables\n    M<-abs(cor(trainingclean[,2:53]))\n    diag(M)<-0\n    which(M>.8, arr.ind=T)\n    # Lots of high correlations\n# Consider pca - must apply same pcas to test set as used for training set!\n# Sample code:\n\n    preProc<-preProcess(log10(trainingclean[,2:53]+.0001), method=\"pca\", pcaComp=2)\n    pcatrain<- predict(preProc, log10(trainingclean[,2:53]+.0001))\n    modelFit<- train(outcomes~., data=pcatrain, method=\"glm\")\n\n    pcatest<- predict(preProc, log10(testingclean[,2:53] +.0001))\n    confusionMatrix(outcomes, predict(modelFit, testPC))\n\n# Try out a few models at this point\n    library(caret)\n    glm.model<-train(trainingclean[,2:53], outcomes, method=\"glm\", na.action=na.omit)\n\n    glm.model$results     #Accuracy of .902, not bad\n\n    confusionMatrix(outcomes, predict(glm.model, trainingclean[,2:53]))\n\n    rf.model<-train(trainingclean[,2:53], outcomes, method=\"rf\")\n",
    "created" : 1431989057855.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "554472966",
    "id" : "CAACB702",
    "lastKnownWriteTime" : 1431992232,
    "path" : "P:/Education/Coursera Courses/Practical Machine Learning/PracticalMachineLearningCP/Exploratory data analysis.R",
    "project_path" : "Exploratory data analysis.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}