if ("pml-training.csv" %in% list.files(".")) {
print("yay!")
}
if ("pml-training.csv" %in% list.files(".")) {
print("yay!")
} else { print("boo")}
if ("pml-training.csv" %in% list.files(".")) {
print("yay!")
} else { print("downloading")
download.file(
"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
destfile="./pml-training.csv")
}
f ("pml-training.csv" %in% list.files(".")) {
print("yay!")
}
if ("pml-testing.csv" %in% list.files(".")) {
print("yay!")
}
if ("pml-training.csv" %in% list.files(".")) {
print("yay!")
}
if ("pml-testing.csv" %in% list.files(".")) {
} else { print("downloading")
download.file(
"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
destfile="./pml-esting.csv")
}
training<-read.csv("./pml-training.csv", header=T)
testing<-read.csv("./pnl-testing.csv", header=T)
testing<-read.csv("./pml-testing.csv", header=T)
if ("pml-testing.csv" %in% list.files(".")) {
} else { print("downloading")
download.file(
"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
destfile="./pml-testing.csv")
}
testing<-read.csv("./pml-testing.csv", header=T)
summary(training)[1:20]
summary(training)[1:20,]
summary(training)[,1:20]
summary(training[,1:20])
help(rowsum)
summary(training[,21:40])
attach(training)
head(stddev_roll_belt^2-var_roll_belt,20)
head(stddev_roll_belt)
summary(training[,41:60])
summary(training[,61:80])
summary(training[,81,100])
summary(training[,81:100])
summary(training[,101:120])
summary(training[,121:140])
summary(training[,141:160])
summary(training[,1:20])
dim(training[-c(1,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )])
testing
1-(19216/19622)
testing[order(testing$cvtd_timestamp)]
testing[order(testing$cvtd_timestamp),]
trainingclean<-training[-c(1,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]
testingclean<-testing[-c(1,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]
summary(trainingclean)
d<-(sqrt(accel_belt_x^2+accel_belt_y^2+accel_belt_x^2)-total_accel_belt)
head(d)
d2<-sqrt(roll_belt^2+pitch_belt^2+yaw_belt^2)-total_accel_belt)
d2<-(sqrt(roll_belt^2+pitch_belt^2+yaw_belt^2)-total_accel_belt)
head(d2)
d3<-(sqrt(gyros_belt_x^2+gyros_belt_y^2+gyros_belt_x^2)-total_accel_belt)
head(d3)
head(total_accel_belt)
dim(trainingClean)[1]
dim(trainingclean)[1]
traininclean[,54]
trainingclean[,54]
outcomes<-c()
for (i in 1:dim(trainingclean)[1]) {
if (trainingclean[i,54]=="A"){
outcomes[i]<-"Right"
} else {
outcomes[i]<-"Wrong"
}
}
head(trainingclean[,54])
help(train)
library(caret)
help(train)
t<-train(trainingclean[,1:53], outcomes, method="rf")
t<-train(trainingclean[,1:53], outcomes, method="glm")
warnings()
summary(trainingclean)
t<-train(trainingclean[,2:53], outcomes, method="glm")
dettach(training)
detach(training)
t<-train(trainingclean[,2:53], outcomes, method="glm")
warnings()
t<-train(trainingclean[,2:5], outcomes, method="glm")
summary(trainingclean[,2:53])
str(trainingclean[,2:53])
trainingclean[,4]<-as.numeric(trainingclean[,4])
str(trainingclean[,2:53])
trainingclean[,5]<-as.numeric(trainingclean[,5])
str(trainingclean[,2:53])
t<-train(trainingclean[,2:5], outcomes, method="glm")
t<-train(outcomes~trainingclean[,2:53], method="glm")
t<-train(outcomes~., data=trainingclean[,2:53], method="glm")
t<-train(outcomes~., data=trainingclean[,2:53], method="lm")
t<-train(trainingclean[,2:5], outcomes, method="glm", na.action=na.omit)
library(mlbench)
data(Sonar)
set.seed(107)
inTrain <- createDataPartition(y = Sonar$Class,
+ ## the outcome data are needed
+ p = .75,
+ ## The percentage of data in the
+ ## training set
+ list = FALSE)
## The format of the results
## The output is a set of integers for the rows of Sonar
## that belong in the training set.
str(inTrain)
install.packages("mlbench")
library(mlbench)
data(Sonar)
set.seed(107)
inTrain <- createDataPartition(y = Sonar$Class,
+ ## the outcome data are needed
+ p = .75,
inTrain <- createDataPartition(y = Sonar$Class,
## the outcome data are needed
p = .75,
## The percentage of data in the
## training set
list = FALSE)
str(inTrain)
training <- Sonar[ inTrain,]
testing <- Sonar[-inTrain,]
nrow(training)
plsFit <- train(Class ~ ., data = training,  method = "pls",
## Center and scale the predictors for the training
## set and all future samples.
preProc = c("center", "scale"))
plsFit <- train(Class ~ ., data = training,  method = "pls",
## Center and scale the predictors for the training
## set and all future samples.
preProc = c("center", "scale"))
sum(complete.cases(trainingclean))
dim(trainingclean)
?glm
glm.1<-glm(outcomes~., data=trainingclean[,2:53])
glm.1<-glm(outcomes~., data=trainingclean[,2:53], family="logit")
glm.1<-glm(outcomes~., data=trainingclean[,2:53], family="binomial")
glm.1<-glm(outcomes~., data=trainingclean[,2:53], family="binomial(link=logit)")
glm.1<-glm(outcomes~., data=trainingclean[,2:53], family=("binomial", link="logit"))
glm.1<-glm(outcomes~., data=trainingclean[,2:53], family("binomial", link="logit"))
glm.1<-glm(outcomes~., data=trainingclean[,2:53], family(binomial, link="logit"))
glm.1<-glm(outcomes~., data=trainingclean[,2:53], family="binomial", link="logit")
glm.1<-glm(outcomes~., data=trainingclean[,2:53], family="quasibinomial")
head(outcomes)
str(outcomes)
?factor
outcomes<-factor(levels="Right", "Wrong")
for (i in 1:dim(trainingclean)[1]) {
if (trainingclean[i,54]=="A"){
outcomes[i]<-"Right"
} else {
outcomes[i]<-"Wrong"
}
}
str(outcomes)
head(outcomes)
outcomes<-factor(levels=c("Right", "Wrong"))
for (i in 1:dim(trainingclean)[1]) {
if (trainingclean[i,54]=="A"){
outcomes[i]<-"Right"
} else {
outcomes[i]<-"Wrong"
}
}
str(outcomes)
head(outcomes)
dim(outcomes)
length(outcomes)
t<-train(trainingclean[,2:53], outcomes, method="glm", na.action=na.omit)
library(caret)
t<-train(trainingclean[,2:53], outcomes, method="glm", na.action=na.omit)
warnings()
str(t)
t$results
rf.model<-train(trainingclean[,2:53], outcomes, method="rf")
nsv<- nearZeroVar(trainingclean, saveMetrics=TRUE)
nsv
M<-abs(cor(trainingclean[,2:53]))
diag(M)<-0
which(M>.8, arr.ind=T)
preProc<-preProcess(log10(trainingclean[,2:53]+.0001), method="pca", pcaComp=2)
preProc<-preProcess(log10(trainingclean[,2:53]+1), method="pca", pcaComp=2)
confusionMatrix(outcomes, predict(glm.model, trainingclean[,2:53]))
confusionMatrix(outcomes, predict(t, trainingclean[,2:53]))
training<-read.csv("./pml-training.csv", header=T)
testing<-read.csv("./pml-testing.csv", header=T)
library(caret)
trainIndex<-createDataPartition(training[,160], p=.8, list=FALSE)
validationclean<-training[-trainIndex,-c(1,2,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]
trainingclean<-training[trainIndex, -c(1,2,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]
set.seed(3450)
trainIndex<-createDataPartition(training[,160], p=.8, list=FALSE)
validationclean<-training[-trainIndex,-c(1,2,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]
trainingclean<-training[trainIndex, -c(1,2,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]
testingclean<-testing[-c(1,2,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]
outcomes<-factor(levels=c("Right", "Wrong"))
for (i in 1:dim(trainingclean)[1]) {
if (trainingclean[i,53]=="A"){
outcomes[i]<-"Right"
} else {
outcomes[i]<-"Wrong"
}
}
nsv<- nearZeroVar(trainingclean, saveMetrics=TRUE)
nsv
M<-abs(cor(trainingclean[,1:52]))
diag(M)<-0
which(M>.8, arr.ind=T)
library(caret)
glm.model<-train(trainingclean[,1:52], outcomes, method="glm", na.action=na.omit)
glm.model$results     #Accuracy of .902, not bad
confusionMatrix(outcomes, predict(glm.model, trainingclean[,1:52]))
rf.model<-train(trainingclean[,1:52], outcomes, method="rf")
rf.model<-train(trainingclean[,1:52], outcomes, method="rf")
preProc<-preProcess(trainingclean[,1:52], method="pca", pcaComp=2)
pcatrain<- predict(preProc, trainingclean[,1:52])
modelFit<- train(outcomes~., data=pcatrain, method="glm")
pcatest<- predict(preProc,testingclean[,1:52])
confusionMatrix(outcomes, predict(modelFit, testPC))
confusionMatrix(outcomes, predict(modelFit, pcatest))
head(testingclean)
validationoutcomes<-factor(levels=c("Right", "Wrong"))
for (i in 1:dim(validationclean)[1]) {
if (validationclean[i,53]=="A"){
validationoutcomes[i]<-"Right"
} else {
validationoutcomes[i]<-"Wrong"
}
}
confusionMatrix(validationoutcomes, predict(modelFit, pcatest))
pcavalidation<- predict(preProc,validationclean[,1:52])
confusionMatrix(validationoutcomes, predict(modelFit, pcavalidation))
modelFitt$result
modelFit$result
preProc<-preProcess(trainingclean[,1:52], method="pca", thresh=.8)
pcatrain<- predict(preProc, trainingclean[,1:52])
modelFit<- train(outcomes~., data=pcatrain, method="glm")
modelFit$result
pcavalidation<- predict(preProc,validationclean[,1:52])
confusionMatrix(validationoutcomes, predict(modelFit, pcavalidation))
confusionMatrix(validationoutcomes, predict(glm.model, validationclean[,1:52]))
preProc<-preProcess(trainingclean[,1:52], method="pca", thresh=.9)
pcatrain<- predict(preProc, trainingclean[,1:52])
modelFit<- train(outcomes~., data=pcatrain, method="glm")
modelFit$result
glm.model2<-train(trainingclean[,1:52], trainingclean[,53], method="glm")
warnings()
?train
names(getModelInfo())
rpart.model<-train(trainingclean[,1:52], trainingclean[,53], method="rpart")
rpart.model$result
confusionMatrix(validationoutcomes, predict(rpart.model, validationclean[,1:52]))
confusionMatrix(validationclean[,53], predict(rpart.model, validationclean[,1:52]))
rf.model<-train(trainingclean[,1:52], outcomes, method="rf")
rf.pca.model<-train(pcatrain, trainingclean[,53], method="rf")
rm(list=ls())
training<-read.csv("./pml-training.csv", header=T)
testing<-read.csv("./pml-testing.csv", header=T)
library(caret)
set.seed(3450)
trainIndex<-createDataPartition(training[,160], p=.8, list=FALSE)
validationclean<-training[-trainIndex,-c(1,2,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]
trainingclean<-training[trainIndex, -c(1,2,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]
testingclean<-testing[-c(1,2,3:7, 12:36, 50:59, 69:83, 87:101, 103:112,125:139, 141:150  )]
nsv<- nearZeroVar(trainingclean, saveMetrics=TRUE)
nsv
M<-abs(cor(trainingclean[,1:52]))
diag(M)<-0
which(M>.8, arr.ind=T)
par(mfrow=(2,2))
for (i in 1:4) {
hist(trainingclean[,i])
}
par(mfrow=c(2,2))
for (i in 1:4) {
hist(trainingclean[,i])
}
for (i in 1:4) {
hist(trainingclean[,i], main=paste(names(trainingclean[,i])))
}
names(trainingclean[,1])
head(trainingclean[,1])
name(trainingclean[,1])
?names
str(trainingclean[,1])
for (i in 1:4) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 5:8) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 9:12) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 13:16) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 17:20) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 21:24) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 25:28) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 29:32) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 33:36) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 37:40) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 41:44) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 45:48) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 49:52) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
hist(trainingclean[,53], main=paste(names(trainingclean)[53]))
for (i in 1:4) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
?boxcox
?boxplot
boxplot(trainingclean[,1]|trainingclean[,53])
boxplot(trainingclean[,1]~trainingclean[,53])
par(mfrow=c(2,2))
for (i in 1:4) {
boxplot(trainingclean[,i]~trainingclean[,53])
}
for (i in 1:4) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 5:8) {
hist(trainingclean[,i], main=paste(names(trainingclean)[i]))
}
for (i in 5:8) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 9:12) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 13:16) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 17:20) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 21:24) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 25:28) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 29:32) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 33:36) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 37:40) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 41:44) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 45:48) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
for (i in 49:52) {
boxplot(trainingclean[,i]~trainingclean[,53], main=paste(names(trainingclean)[i]))
}
preProc<-preProcess(trainingclean[,1:52], method="pca", thresh=.9)
pcatrain<- predict(preProc, trainingclean[,1:52])
pcavalidation<- predict(preProc,validationclean[,1:52])
rf.model<-train(trainingclean[,1:52], trainingclean[,53], method="rf")
rf.model$result
confusionMatrix(validationclean[,53], predict(rf.model, validationclean[,1:52]))
rf.pca.model<-train(pcatrain, trainingclean[,53], method="rf")
rf.pca.model$result
confusionMatrix(validationclean[,53], predict(rf.pca.model, validationclean[,1:52]))
confusionMatrix(validationclean[,53], predict(rf.pca.model, pcavalidation))
rpart.model<-train(trainingclean[,1:52], trainingclean[,53], method="rpart")
rpart.model$result
confusionMatrix(validationclean[,53], predict(rpart.model, validationclean[,1:52]))
confusionMatrix(validationclean[,53], predict(rf.model, validationclean[,1:52]))
rf.model$result
fitControl<-trainControl(method="repeatedcv", number=10, repeats=10)
rf.model<-train(trainingclean[,1:52], trainingclean[,53], method="rf", trControl=fitControl) #Started this at 8:45 today, done by 9:49, possibly earlier
rf.model$result
rf.model.cv<-train(trainingclean[,1:52], trainingclean[,53], method="rf", trControl=fitControl) #began 10:52
rf.model.cv<-train(head(trainingclean[,1:52], 1000), head(trainingclean[,53],1000), method="rf", trControl=fitControl) #began 10:53, not done by 12:02
head(trainingclean[,1:5], 10)
head(trainingclean[,1:5])
rf.model.cv<-train(head(trainingclean[,1:52], 5000), head(trainingclean[,53],5000), method="rf", trControl=fitControl) #began 10:53, not done by 12:02
rf.model.cv<-train(head(trainingclean[,1:52], 10000), head(trainingclean[,53],10000), method="rf", trControl=fitControl)
rf.model.cv<-train(head(trainingclean[,1:52], 15000), head(trainingclean[,53],15000), method="rf", trControl=fitControl)
rf.model.cv<-train(head(trainingclean[,1:52], 10000), head(trainingclean[,53],10000), method="rf", trControl=fitControl)
proc.time()
system.tim(rf.model.cv<-train(head(trainingclean[,1:52], 10000), head(trainingclean[,53],10000), method="rf", trControl=fitControl))
system.time(rf.model.cv<-train(head(trainingclean[,1:52], 10000), head(trainingclean[,53],10000), method="rf", trControl=fitControl))
system.time(rf.model.cv<-train(head(trainingclean[,1:52], 1000), head(trainingclean[,53],1000), method="rf", trControl=fitControl))
system.time(rf.model.cv<-train(head(trainingclean[,1:52], 5000), head(trainingclean[,53],5000), method="rf", trControl=fitControl))
warnings()
plot(trainingclean[,53])
plot(as.numeric(trainingclean[,53]))
system.time(rf.model.cv<-train(trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:150100),1:52], trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:150100),53], method="rf", trControl=fitControl))
warnings()
summary()trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:150100),1:52])
summary(trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:150100),1:52])
summary(trainingclean[c(1:100),1:52])
summary(trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:15100),1:52])
summary(trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:15100),1:52])
plot(as.numeric(trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:15100),1:52]))
plot(as.numeric(trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:15100),53]))
system.time(rf.model.cv<-train(trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:15100),1:52], trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:150100),53], method="rf", trControl=fitControl))
system.time(rf.model.cv<-train(trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:15100),1:52], trainingclean[c(1:100, 5000:5100, 9900:10000, 12000:12100, 15000:15100),53], method="rf", trControl=fitControl))
rf.model.cv$result
rf.pca.model
rf.model
rf.model.cv
trellis.par.set(caretTheme())
plot(rf.model.cv)
plot(rf.model)
system.time(rf.model.cv<-train(trainingclean[c(1:200, 5000:5200, 9900:10100, 12000:12200, 15000:15200),1:52], trainingclean[c(1:200, 5000:5200, 9900:10100, 12000:12200, 15000:15200),53], method="rf", trControl=fitControl))
rf.model.cv
plot(rf.model.cv)
confusionMatrix(validationclean[,53], predict(rf.model.cv, validationclean[,1:52]))
system.time(rf.model.cv<-train(trainingclean[c(1:200, 5000:5200, 9900:10100, 12000:12200, 15000:15200),1:52], trainingclean[c(1:200, 5000:5200, 9900:10100, 12000:12200, 15000:15200),53], method="rf"))
rf.model.cv
nb.model<-train(trainingclean[,1:52], trainingclean[,53], method="nb")
nb.model
confusionMatrix(validationclean[,53], predict(nb.model, validationclean[,1:52]))
?registerDoMC
??registerDoMC
?sample
set.seed(4056)
smalltraining<-sample(trainingclean, size=1000)
smalltraining<-trainingclean[sample(1:length(trainingclean), size=1000), ]
dim(trainingclean)[1]
smalltraining<-trainingclean[sample(1:dim(trainingclean)[1], size=1000), ]
set.seed(4056)
smalltraining<-trainingclean[sample(1:dim(trainingclean)[1], size=1000), ]
nnet.model.small<-train(smalltraining[,1:52], small training[,53], method="nnet")
nnet.model.small
confusionMatrix(validationclean[,53], predict(nnet.model.small, validationclean[,1:52]))
rpart.model
rpart.model$finalModel
print(rpart.model$finalModel)
plot(rpart.model$finalModel)
trellis.par.set()
plot(rpart.model$finalModel)
par(mfrow=c(1,1))
plot(rpart.model$finalModel)
plot(rpart.model$finalModel, uniform=T, main="Classification Tree")
text(rpart.model$finalModel, use.n=T, all=T, cex=.8)
plot(rpart.model$finalModel, uniform=T, main="Classification Tree")
text(rpart.model$finalModel, use.n=T, all=T, cex=.5)
rf.model
rf.model$finalModel
plot(rf.model$finalModel)
rm(rf.model.cv)
View(trainIndex)
nnet.model.small<-train(smalltraining[,1:52], smalltraining[,53], method="nnet")
nnet.model.small
confusionMatrix(validationclean[,53], predict(nnet.model.small, validationclean[,1:52]))
set.seed(4056)
smalltraining<-trainingclean[sample(1:dim(trainingclean)[1], size=5000), ]
nnet.model.small<-train(smalltraining[,1:52], smalltraining[,53], method="nnet")
nnet.model.small
confusionMatrix(validationclean[,53], predict(nnet.model.small, validationclean[,1:52]))
gmb.model<-train(smalltraining[,1:52], smalltraining[,53], method="gmb")
gmb.model
confusionMatrix(validationclean[,53], predict(gbm.model, validationclean[,1:52]))
gbm.model<-train(smalltraining[,1:52], smalltraining[,53], method="gbm")
gbm.model
confusionMatrix(validationclean[,53], predict(gbm.model, validationclean[,1:52]))
